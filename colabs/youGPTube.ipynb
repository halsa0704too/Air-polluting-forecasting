{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsVZdJM3hyXL"
      },
      "source": [
        "# YouGPTube ü¶æ\n",
        "\n",
        "## TL;DR üëá\n",
        "\n",
        "* Summarize any YouTube video using whisper and chatGPT\n",
        "\n",
        "## How it works ü§î\n",
        "\n",
        "![yougptube](https://user-images.githubusercontent.com/18450628/229377710-95fb8645-3d71-47d0-b3ba-0fd05941b083.png)\n",
        "\n",
        "Here are the main steps:\n",
        "\n",
        "1) Extract the audio using youtube-dl\n",
        "2) Process the audio into smaller chunks\n",
        "3) Each chunk is transcribed using whisper, OpenAI's powerful speech2text model\n",
        "4) Each transcription is summarized using ChatGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcMFoCb8hyXN"
      },
      "source": [
        "## Imports and dependenciesÔ∏è ‚öôÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8-0zARMOhyXO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import youtube_dl\n",
        "from youtube_dl.utils import DownloadError\n",
        "import google.generativeai as genai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Configure Gemini (Google Generative AI)\n",
        "GOOGLE_API_KEY = \"AIzaSyBasyDzmOWkXp7PZ8N-PedYZoqFwmOW5tY\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Ensure the Google API key is set\n",
        "assert GOOGLE_API_KEY is not None, \"Please set your Google API key in the environment variable GOOGLE_API_KEY\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_yexqJyhyXP"
      },
      "source": [
        "## Utility functions üîã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "f1308lDbhyXP"
      },
      "outputs": [],
      "source": [
        "def find_audio_files(path, extension=\".mp3\"):\n",
        "    \"\"\"Recursively find all files with extension in path.\"\"\"\n",
        "    audio_files = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for f in files:\n",
        "            if f.endswith(extension):\n",
        "                audio_files.append(os.path.join(root, f))\n",
        "\n",
        "    return audio_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Oww3Vw7JhyXQ"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "\n",
        "def youtube_to_mp3(youtube_url: str, output_dir: str) -> str:\n",
        "    \"\"\"Download the audio from a YouTube video, save it to output_dir as an .mp3 file.\n",
        "\n",
        "    Returns the filename of the saved audio file.\n",
        "    \"\"\"\n",
        "    # Configuration for youtube-dl\n",
        "    ydl_config = {\n",
        "        \"format\": \"bestaudio/best\",\n",
        "        \"postprocessors\": [\n",
        "            {\n",
        "                \"key\": \"FFmpegExtractAudio\",\n",
        "                \"preferredcodec\": \"mp3\",\n",
        "                \"preferredquality\": \"192\",\n",
        "            }\n",
        "        ],\n",
        "        \"outtmpl\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),\n",
        "        \"verbose\": True,\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    print(f\"Downloading video from {youtube_url}\")\n",
        "\n",
        "    try:\n",
        "        # Use yt-dlp instead of youtube-dl\n",
        "        with yt_dlp.YoutubeDL(ydl_config) as ydl:\n",
        "            ydl.download([youtube_url])\n",
        "    except DownloadError as e:\n",
        "        print(f\"Initial download failed due to: {e}. Retrying...\")\n",
        "        # Use yt-dlp instead of youtube-dl\n",
        "        with yt_dlp.YoutubeDL(ydl_config) as ydl:\n",
        "            ydl.download([youtube_url])\n",
        "\n",
        "    audio_files = find_audio_files(output_dir)\n",
        "    if not audio_files:\n",
        "        raise FileNotFoundError(\"No audio file was found in the output directory.\")\n",
        "\n",
        "    return audio_files[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp0v5EuehyXQ"
      },
      "source": [
        "## Download youtube audio üîà"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSEgYlHvhyXQ"
      },
      "source": [
        "## Chunk the audio üç™\n",
        "\n",
        "Chunking is necessary in the case where we have very long audio files, since both whisper and ChatGPT have limits of how much audio/text you can process in one go.\n",
        "It is not necessary for shorter videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fVbB9L1khyXR"
      },
      "outputs": [],
      "source": [
        "def chunk_audio(filename, segment_length: int, output_dir, output_format=\".mp3\"):\n",
        "    \"\"\"Segment the audio into chunks of specified length (in seconds) and save them.\n",
        "\n",
        "    Args:\n",
        "        filename (str): Path to the audio file.\n",
        "        segment_length (int): Length of each segment in seconds.\n",
        "        output_dir (str): Directory to save the audio chunks.\n",
        "        output_format (str): File format for the output audio chunks (default: .mp3).\n",
        "\n",
        "    Returns:\n",
        "        list: Sorted list of paths to the chunked audio files.\n",
        "    \"\"\"\n",
        "    if segment_length <= 0:\n",
        "        raise ValueError(\"Segment length must be greater than 0.\")\n",
        "\n",
        "    if not os.path.exists(filename):\n",
        "        raise FileNotFoundError(f\"Audio file not found: {filename}\")\n",
        "\n",
        "    print(f\"Chunking audio into {segment_length}-second segments...\")\n",
        "\n",
        "    if not os.path.isdir(output_dir):\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load the audio file\n",
        "    audio, sr = librosa.load(filename, sr=44100)\n",
        "\n",
        "    # Calculate duration and number of segments\n",
        "    duration = librosa.get_duration(y=audio, sr=sr)\n",
        "    num_segments = int(duration / segment_length) + 1\n",
        "\n",
        "    print(f\"Total duration: {duration:.2f} seconds. Creating {num_segments} chunks...\")\n",
        "\n",
        "    # Segment the audio and save\n",
        "    for i in range(num_segments):\n",
        "        start = int(i * segment_length * sr)\n",
        "        end = int(min((i + 1) * segment_length * sr, len(audio)))\n",
        "        segment = audio[start:end]\n",
        "        segment_file = os.path.join(output_dir, f\"segment_{i}{output_format}\")\n",
        "        sf.write(segment_file, segment, sr)\n",
        "        print(f\"Saved segment {i + 1}/{num_segments} to {segment_file}\")\n",
        "\n",
        "    chunked_audio_files = find_audio_files(output_dir, extension=output_format)\n",
        "    return sorted(chunked_audio_files)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SmjfbymhyXR"
      },
      "source": [
        "## Speech2text üó£\n",
        "\n",
        "Here we use OpenAI's whisper model to transcribe audio files to text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "rFaWnSt2hyXS"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "\n",
        "def transcribe_audio(audio_files: list, output_file=None, model_size=\"base\") -> list:\n",
        "    \"\"\"Transcribe audio files into text using the local Whisper model.\n",
        "\n",
        "    Args:\n",
        "        audio_files (list): List of paths to audio files.\n",
        "        output_file (str): Optional file to save all transcripts.\n",
        "        model_size (str): The size of the Whisper model to use (e.g., \"tiny\", \"base\", \"small\", \"medium\", \"large\").\n",
        "\n",
        "    Returns:\n",
        "        list: A list of transcripts for each audio file.\n",
        "    \"\"\"\n",
        "    print(\"Loading Whisper model...\")\n",
        "    model = whisper.load_model(model_size)\n",
        "\n",
        "    transcripts = []\n",
        "    for audio_file in audio_files:\n",
        "        print(f\"Processing file: {audio_file}\")\n",
        "        # Perform transcription\n",
        "        result = model.transcribe(audio_file)\n",
        "        transcript = result[\"text\"]\n",
        "        transcripts.append(transcript)\n",
        "\n",
        "    if output_file is not None:\n",
        "        # Save all transcripts to a .txt file\n",
        "        with open(output_file, \"w\") as file:\n",
        "            for transcript in transcripts:\n",
        "                file.write(transcript + \"\\n\")\n",
        "\n",
        "    return transcripts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxRn2dWThyXS"
      },
      "source": [
        "## Summarize üìù\n",
        "\n",
        "Here we ask chatGPT to take the raw transcripts and transcribe them for us to short bullet points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "bje_gJfNhyXS"
      },
      "outputs": [],
      "source": [
        "# from google.generativeai import genai\n",
        "\n",
        "def summarize(chunks, system_prompt, model='google-gemini', output_file=None):\n",
        "    summaries = []\n",
        "\n",
        "    # Combine chunks into one text input\n",
        "    full_input = system_prompt + \"\\n\".join(chunks)\n",
        "\n",
        "    # Generate summary using Gemini model (or similar API call)\n",
        "    try:\n",
        "        response = genai.generate_text(prompt=full_input, max_output_tokens=150)\n",
        "        summary = response.result  # This will be the generated summary\n",
        "        summaries.append(summary)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during summary generation: {e}\")\n",
        "\n",
        "    # Optionally write to output file\n",
        "    if output_file:\n",
        "        with open(output_file, 'w') as f:\n",
        "            f.write(\"\\n\".join(summaries))\n",
        "\n",
        "    return summaries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaWnkFyZhyXT"
      },
      "source": [
        "## Putting it all together üç±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "U1R75S6ThyXT"
      },
      "outputs": [],
      "source": [
        "def summarize_youtube_video(youtube_url, outputs_dir):\n",
        "    raw_audio_dir = f\"{outputs_dir}/raw_audio/\"\n",
        "    chunks_dir = f\"{outputs_dir}/chunks\"\n",
        "    transcripts_file = f\"{outputs_dir}/transcripts.txt\"\n",
        "    summary_file = f\"{outputs_dir}/summary.txt\"\n",
        "    segment_length = 10 * 60  # chunk to 10 minute segments\n",
        "\n",
        "    if os.path.exists(outputs_dir):\n",
        "        # delete the outputs_dir folder and start from scratch\n",
        "        shutil.rmtree(outputs_dir)\n",
        "        os.mkdir(outputs_dir)\n",
        "\n",
        "    # Download the video using youtube-dl\n",
        "    audio_filename = youtube_to_mp3(youtube_url, output_dir=raw_audio_dir)\n",
        "\n",
        "    # Chunk each audio file into shorter segments\n",
        "    chunked_audio_files = chunk_audio(\n",
        "        audio_filename, segment_length=segment_length, output_dir=chunks_dir\n",
        "    )\n",
        "\n",
        "    # Transcribe each chunked audio file using Whisper speech-to-text\n",
        "    transcriptions = transcribe_audio(chunked_audio_files, transcripts_file)\n",
        "\n",
        "    # Summarize each transcription using Google Gemini\n",
        "    system_prompt = \"\"\"\n",
        "    You are a helpful assistant that summarizes YouTube videos.\n",
        "    You are provided chunks of raw audio that were transcribed from the video's audio.\n",
        "    Summarize the current chunk into succinct and clear bullet points of its contents.\n",
        "    \"\"\"\n",
        "    summaries = summarize(\n",
        "        transcriptions, system_prompt=system_prompt, output_file=summary_file\n",
        "    )\n",
        "\n",
        "    system_prompt_tldr = \"\"\"\n",
        "    You are a helpful assistant that summarizes YouTube videos.\n",
        "    Someone has already summarized the video into key points.\n",
        "    Summarize the key points into one or two sentences that capture the essence of the video.\n",
        "    \"\"\"\n",
        "    # Combine all summaries into a long summary\n",
        "    long_summary = \"\\n\".join(summaries)\n",
        "\n",
        "    # Summarize the long summary to get the final short summary\n",
        "    short_summary = summarize(\n",
        "        [long_summary], system_prompt=system_prompt_tldr, output_file=summary_file\n",
        "    )[0]\n",
        "\n",
        "    return long_summary, short_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ddZqdBzqhyXT",
        "outputId": "f88e19e1-763c-402c-ac17-bd3200f02c8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.12.23 from yt-dlp/yt-dlp [65cf46cdd] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': 'outputs//raw_audio/%(title)s.%(ext)s', 'verbose': True, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: certifi-2024.12.14, requests-2.32.3, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.2.3, websockets-14.1\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1837 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading video from https://www.youtube.com/watch?v=g1pb2aK2we4\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=g1pb2aK2we4\n",
            "[youtube] g1pb2aK2we4: Downloading webpage\n",
            "[youtube] g1pb2aK2we4: Downloading ios player API JSON\n",
            "[youtube] g1pb2aK2we4: Downloading mweb player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] [youtube] g1pb2aK2we4: ios client https formats require a PO Token which was not provided. They will be skipped as they may yield HTTP Error 403. You can manually pass a PO Token for this client with --extractor-args \"youtube:po_token=ios+XXX. For more information, refer to  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#po-token-guide . To enable these broken formats anyway, pass --extractor-args \"youtube:formats=missing_pot\"\n",
            "[debug] Loading youtube-nsig.03dbdfab from cache\n",
            "[debug] [youtube] Decrypted nsig pdXWIpxBD6Gj8NuX5 => -BVKB_bikV8Edw\n",
            "[debug] Loading youtube-nsig.03dbdfab from cache\n",
            "[debug] [youtube] Decrypted nsig uNU0SXiYdo8c662Y3 => sl-Fq8v367TI9w\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] g1pb2aK2we4: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec, channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] g1pb2aK2we4: Downloading 1 format(s): 251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr2---sn-npoe7ns6.googlevideo.com/videoplayback?expire=1735923703&ei=l8N3Z7mOO-PVssUP29X_4AM&ip=34.142.152.38&id=o-ANdAOr3qZrNXv2cF06mosrweZA6gSVaV8rUO898K83FS&itag=251&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1735902103%2C&mh=JU&mm=31%2C26&mn=sn-npoe7ns6%2Csn-30a7rnek&ms=au%2Conr&mv=m&mvi=2&pl=20&rms=au%2Cau&initcwndbps=1821250&bui=AfMhrI88spFZRTdmrJlTA5jyTA1xGSMEOXjJI4ykzmmwCVi8P9RUYoG1K2_H12gvTdl2mTMf-LB34H8V&vprv=1&svpuc=1&mime=audio%2Fwebm&ns=dZelpeMmashvD8rznYN-s4gQ&rqh=1&gir=yes&clen=5840382&dur=302.621&lmt=1727819059976703&mt=1735901818&fvip=5&keepalive=yes&fexp=51326932%2C51331020%2C51335594%2C51371294&c=MWEB&sefc=1&txp=4532434&n=sl-Fq8v367TI9w&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cbui%2Cvprv%2Csvpuc%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRgIhALvbP69rC40tw2Zhy_hX08WB7yi9vt9XZPgocYRsqMsTAiEA0XW9sFFfh3goPO6ggBNg3DUt4Cv1r2W1gCOMkEo5JOY%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=AGluJ3MwRgIhAPhXPgzDMQTOC3WXyqaKrOO0zaEVYlg0-0cqhPiNTtqKAiEA1F5uW-GYd7vz1xxlrqMqih8IyD9Di8XdFj_NRcvGqGQ%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: outputs//raw_audio/How stretching actually changes your muscles - Malachy McHugh.webm\n",
            "[download] 100% of    5.57MiB in 00:00:00 at 23.65MiB/s  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:outputs//raw_audio/How stretching actually changes your muscles - Malachy McHugh.webm'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: outputs//raw_audio/How stretching actually changes your muscles - Malachy McHugh.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:outputs//raw_audio/How stretching actually changes your muscles - Malachy McHugh.webm' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:outputs//raw_audio/How stretching actually changes your muscles - Malachy McHugh.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file outputs//raw_audio/How stretching actually changes your muscles - Malachy McHugh.webm (pass -k to keep)\n",
            "Chunking audio into 600-second segments...\n",
            "Total duration: 302.60 seconds. Creating 1 chunks...\n",
            "Saved segment 1/1 to outputs//chunks/segment_0.mp3\n",
            "Loading Whisper model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: outputs//chunks/segment_0.mp3\n",
            "Error during summary generation: module 'google.generativeai' has no attribute 'generate_text'\n",
            "Error during summary generation: module 'google.generativeai' has no attribute 'generate_text'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-2344ac51cc14>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0moutputs_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"outputs/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mlong_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_youtube_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myoutube_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Print the summaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-2344ac51cc14>\u001b[0m in \u001b[0;36msummarize_youtube_video\u001b[0;34m(youtube_url, outputs_dir)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[1;32m     42\u001b[0m     \u001b[0mlong_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mshort_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlong_summary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_prompt_tldr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msummary_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlong_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# API Key for Google Gemini\n",
        "GOOGLE_API_KEY = \"AIzaSyBasyDzmOWkXp7PZ8N-PedYZoqFwmOW5tY\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Define other necessary functions (find_audio_files, youtube_to_mp3, chunk_audio, transcribe_audio, summarize) before this\n",
        "# ...\n",
        "\n",
        "def summarize_youtube_video(youtube_url, outputs_dir):\n",
        "    raw_audio_dir = f\"{outputs_dir}/raw_audio/\"\n",
        "    chunks_dir = f\"{outputs_dir}/chunks\"\n",
        "    transcripts_file = f\"{outputs_dir}/transcripts.txt\"\n",
        "    summary_file = f\"{outputs_dir}/summary.txt\"\n",
        "    segment_length = 10 * 60  # chunk to 10 minute segments\n",
        "\n",
        "    if os.path.exists(outputs_dir):\n",
        "        shutil.rmtree(outputs_dir)  # Delete old files/folder if exists\n",
        "        os.mkdir(outputs_dir)\n",
        "\n",
        "    # Download the video using yt-dlp\n",
        "    audio_filename = youtube_to_mp3(youtube_url, output_dir=raw_audio_dir)\n",
        "\n",
        "    # Chunk the audio file\n",
        "    chunked_audio_files = chunk_audio(audio_filename, segment_length=segment_length, output_dir=chunks_dir)\n",
        "\n",
        "    # Transcribe audio files to text\n",
        "    transcriptions = transcribe_audio(chunked_audio_files, transcripts_file)\n",
        "\n",
        "    # Summarize transcriptions\n",
        "    system_prompt = \"\"\"\n",
        "    You are a helpful assistant that summarizes youtube videos.\n",
        "    You are provided chunks of raw audio that were transcribed from the video's audio.\n",
        "    Summarize the current chunk to succinct and clear bullet points of its contents.\n",
        "    \"\"\"\n",
        "    summaries = summarize(transcriptions, system_prompt=system_prompt, output_file=summary_file)\n",
        "\n",
        "    # Create TL;DR summary\n",
        "    system_prompt_tldr = \"\"\"\n",
        "    You are a helpful assistant that summarizes youtube videos.\n",
        "    Someone has already summarized the video to key points.\n",
        "    Summarize the key points to one or two sentences that capture the essence of the video.\n",
        "    \"\"\"\n",
        "    long_summary = \"\\n\".join(summaries)\n",
        "    short_summary = summarize([long_summary], system_prompt=system_prompt_tldr, output_file=summary_file)[0]\n",
        "\n",
        "    return long_summary, short_summary\n",
        "\n",
        "\n",
        "# Example use\n",
        "youtube_url = \"https://www.youtube.com/watch?v=g1pb2aK2we4\"\n",
        "outputs_dir = \"outputs/\"\n",
        "\n",
        "long_summary, short_summary = summarize_youtube_video(youtube_url, outputs_dir)\n",
        "\n",
        "# Print the summaries\n",
        "print(\"Summaries:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Long summary:\")\n",
        "print(\"=\" * 80)\n",
        "print(long_summary)\n",
        "print()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Video - TL;DR\")\n",
        "print(\"=\" * 80)\n",
        "print(short_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fM8f_xqqhyXU"
      },
      "outputs": [],
      "source": [
        "youtube_url = \"https://www.youtube.com/watch?v=Yf1o0TQzry8\"\n",
        "outputs_dir = \"outputs/\"\n",
        "\n",
        "long_summary, short_summary = summarize_youtube_video(youtube_url, outputs_dir)\n",
        "\n",
        "print(\"Summaries:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Long summary:\")\n",
        "print(\"=\" * 80)\n",
        "print(long_summary)\n",
        "print()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"Video - TL;DR\")\n",
        "print(\"=\" * 80)\n",
        "print(short_summary)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "youGPTube",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}